{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Car Price prediction\n\n<img src=\"https://whatcar.vn/media/2018/09/car-lot-940x470.jpg\"/>\n\n## Прогнозирование стоимости автомобиля по характеристикам\n*Этот ноутбук является шаблоном (Baseline) к текущему соревнованию и не служит готовым решением!*   \nВы можете использовать его как основу для построения своего решения.\n\n\n> **Baseline** создается больше как шаблон, где можно посмотреть, как происходит обращение с входящими данными и что нужно получить на выходе. При этом ML начинка может быть достаточно простой. Это помогает быстрее приступить к самому ML, а не тратить ценное время на инженерные задачи. \nТакже baseline является хорошей опорной точкой по метрике. Если наше решение хуже baseline -  мы явно делаем что-то не так и стоит попробовать другой путь) ","metadata":{}},{"cell_type":"markdown","source":"## В baseline мы сделаем следующее:\n* Построим \"наивную\"/baseline модель, предсказывающую цену по модели и году выпуска (с ней будем сравнивать другие модели)\n* Обработаем и отнормируем признаки\n* Сделаем первую модель на основе градиентного бустинга с помощью CatBoost\n* Сделаем вторую модель на основе нейронных сетей и сравним результаты\n* Сделаем multi-input нейронную сеть для анализа табличных данных и текста одновременно\n* Добавим в multi-input сеть обработку изображений\n* Осуществим ансамблирование градиентного бустинга и нейронной сети (усреднение их предсказаний)","metadata":{}},{"cell_type":"code","source":"!pip install -q tensorflow==2.3","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-29T19:05:18.78419Z","iopub.execute_input":"2021-05-29T19:05:18.784544Z","iopub.status.idle":"2021-05-29T19:05:28.478677Z","shell.execute_reply.started":"2021-05-29T19:05:18.784514Z","shell.execute_reply":"2021-05-29T19:05:28.477392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#аугментации изображений\n!pip install albumentations -q","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-29T19:05:28.481226Z","iopub.execute_input":"2021-05-29T19:05:28.481658Z","iopub.status.idle":"2021-05-29T19:05:35.874087Z","shell.execute_reply.started":"2021-05-29T19:05:28.48157Z","shell.execute_reply":"2021-05-29T19:05:35.870696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing modules.\nimport random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport albumentations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport sys\nimport PIL\nimport cv2\nimport re\n\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom pylab import rcParams\nfrom itertools import combinations\nfrom scipy.stats import ttest_ind\n\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-05-29T19:06:58.868555Z","iopub.execute_input":"2021-05-29T19:06:58.868965Z","iopub.status.idle":"2021-05-29T19:06:59.179689Z","shell.execute_reply.started":"2021-05-29T19:06:58.868932Z","shell.execute_reply":"2021-05-29T19:06:59.178456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-29T19:07:02.748281Z","iopub.execute_input":"2021-05-29T19:07:02.748672Z","iopub.status.idle":"2021-05-29T19:07:02.754491Z","shell.execute_reply.started":"2021-05-29T19:07:02.748639Z","shell.execute_reply":"2021-05-29T19:07:02.753129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-29T19:07:04.567847Z","iopub.execute_input":"2021-05-29T19:07:04.568208Z","iopub.status.idle":"2021-05-29T19:07:04.573475Z","shell.execute_reply.started":"2021-05-29T19:07:04.568177Z","shell.execute_reply":"2021-05-29T19:07:04.572047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip freeze > requirements.txt","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-26T05:39:25.817436Z","iopub.execute_input":"2021-05-26T05:39:25.817917Z","iopub.status.idle":"2021-05-26T05:39:28.34931Z","shell.execute_reply.started":"2021-05-26T05:39:25.81788Z","shell.execute_reply":"2021-05-26T05:39:28.348215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA","metadata":{}},{"cell_type":"markdown","source":"Посмотрим на типы признаков:\n\n* bodyType - категориальный\n* brand - категориальный\n* color - категориальный\n* description - текстовый\n* engineDisplacement - числовой, представленный как текст\n* enginePower - числовой, представленный как текст\n* fuelType - категориальный\n* mileage - числовой\n* modelDate - числовой\n* model_info - категориальный\n* name - категориальный, желательно сократить размерность\n* numberOfDoors - категориальный\n* price - числовой, целевой\n* productionDate - числовой\n* sell_id - изображение (файл доступен по адресу, основанному на sell_id)\n* vehicleConfiguration - не используется (комбинация других столбцов)\n* vehicleTransmission - категориальный\n* Владельцы - категориальный\n* Владение - числовой, представленный как текст\n* ПТС - категориальный\n* Привод - категориальный\n* Руль - категориальный","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '../input/sf-dst-car-price-prediction-part2/'\ntrain = pd.read_csv(DATA_DIR + 'train.csv')\ntest = pd.read_csv(DATA_DIR + 'test.csv')\nsample_submission = pd.read_csv(DATA_DIR + 'sample_submission.csv')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-05-29T19:07:10.422957Z","iopub.execute_input":"2021-05-29T19:07:10.42334Z","iopub.status.idle":"2021-05-29T19:07:10.876241Z","shell.execute_reply.started":"2021-05-29T19:07:10.42331Z","shell.execute_reply":"2021-05-29T19:07:10.87521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T19:00:06.778532Z","iopub.execute_input":"2021-05-25T19:00:06.779028Z","iopub.status.idle":"2021-05-25T19:00:06.815001Z","shell.execute_reply.started":"2021-05-25T19:00:06.778933Z","shell.execute_reply":"2021-05-25T19:00:06.814084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T19:00:06.816573Z","iopub.execute_input":"2021-05-25T19:00:06.816979Z","iopub.status.idle":"2021-05-25T19:00:06.8949Z","shell.execute_reply.started":"2021-05-25T19:00:06.816945Z","shell.execute_reply":"2021-05-25T19:00:06.893859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: Создадим \"наивную\" модель \nЭта модель будет предсказывать среднюю цену по модели и году выпуска. \nC ней будем сравнивать другие модели.\n\n","metadata":{}},{"cell_type":"code","source":"# split данных\ndata_train, data_test = train_test_split(train, test_size=0.15, shuffle=True, random_state=RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:07:14.585678Z","iopub.execute_input":"2021-05-29T19:07:14.586058Z","iopub.status.idle":"2021-05-29T19:07:14.602955Z","shell.execute_reply.started":"2021-05-29T19:07:14.586028Z","shell.execute_reply":"2021-05-29T19:07:14.601665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Наивная модель\npredicts = []\nfor index, row in pd.DataFrame(data_test[['model_info', 'productionDate']]).iterrows():\n    query = f\"model_info == '{row[0]}' and productionDate == '{row[1]}'\"\n    predicts.append(data_train.query(query)['price'].median())\n\n# заполним не найденные совпадения\npredicts = pd.DataFrame(predicts)\npredicts = predicts.fillna(predicts.median())\n\n# округлим\npredicts = (predicts // 1000) * 1000\n\n#оцениваем точность\nprint(f\"Точность наивной модели по метрике MAPE: {(mape(data_test['price'], predicts.values[:, 0]))*100:0.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:07:18.000558Z","iopub.execute_input":"2021-05-29T19:07:18.000971Z","iopub.status.idle":"2021-05-29T19:07:22.787141Z","shell.execute_reply.started":"2021-05-29T19:07:18.000935Z","shell.execute_reply":"2021-05-29T19:07:22.785191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"Проведем быстрый анализ данных для того, чтобы понимать, сможет ли с этими данными работать наш алгоритм.","metadata":{}},{"cell_type":"markdown","source":"Посмотрим, как выглядят распределения числовых признаков:","metadata":{}},{"cell_type":"code","source":"#посмотрим, как выглядят распределения числовых признаков\ndef visualize_distributions(titles_values_dict):\n  columns = min(3, len(titles_values_dict))\n  rows = (len(titles_values_dict) - 1) // columns + 1\n  fig = plt.figure(figsize = (columns * 6, rows * 4))\n  for i, (title, values) in enumerate(titles_values_dict.items()):\n    hist, bins = np.histogram(values, bins = 20)\n    ax = fig.add_subplot(rows, columns, i + 1)\n    ax.bar(bins[:-1], hist, width = (bins[1] - bins[0]) * 0.7)\n    ax.set_title(title)\n  plt.show()\n\nvisualize_distributions({\n    'mileage': train['mileage'].dropna(),\n    'modelDate': train['modelDate'].dropna(),\n    'productionDate': train['productionDate'].dropna()\n})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-25T19:50:36.290306Z","iopub.execute_input":"2021-05-25T19:50:36.290683Z","iopub.status.idle":"2021-05-25T19:50:36.936471Z","shell.execute_reply.started":"2021-05-25T19:50:36.29065Z","shell.execute_reply":"2021-05-25T19:50:36.935204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Итого:\n* CatBoost сможет работать с признаками и в таком виде, но для нейросети нужны нормированные данные.","metadata":{}},{"cell_type":"markdown","source":"# PreProc Tabular Data","metadata":{}},{"cell_type":"code","source":"#используем все текстовые признаки как категориальные без предобработки\ncategorical_features = ['bodyType', 'brand', 'color', 'engineDisplacement', 'enginePower', 'fuelType', 'model_info', 'name',\n  'numberOfDoors', 'vehicleTransmission', 'Владельцы', 'Владение', 'ПТС', 'Привод', 'Руль']\n\n#используем все числовые признаки\nnumerical_features = ['mileage', 'modelDate', 'productionDate']","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:07:39.376939Z","iopub.execute_input":"2021-05-29T19:07:39.377327Z","iopub.status.idle":"2021-05-29T19:07:39.383745Z","shell.execute_reply.started":"2021-05-29T19:07:39.377293Z","shell.execute_reply":"2021-05-29T19:07:39.381926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ntrain['sample'] = 1 # помечаем где у нас трейн\ntest['sample'] = 0 # помечаем где у нас тест\ntest['price'] = 0 # в тесте у нас нет значения price, мы его должны предсказать, поэтому пока просто заполняем нулями\n\ndata = test.append(train, sort=False).reset_index(drop=True) # объединяем\nprint(train.shape, test.shape, data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:07:44.586066Z","iopub.execute_input":"2021-05-29T19:07:44.58642Z","iopub.status.idle":"2021-05-29T19:07:44.614129Z","shell.execute_reply.started":"2021-05-29T19:07:44.586388Z","shell.execute_reply":"2021-05-29T19:07:44.612228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Посмотрим на корреляцию численных признаков\nпотенциально у нас должна быть зависимость между датой производства автомобиля и датой выпуска автомобиля. Обработаем данную зависимость далее.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:33:08.800666Z","iopub.execute_input":"2021-05-26T11:33:08.801227Z","iopub.status.idle":"2021-05-26T11:33:08.91275Z","shell.execute_reply.started":"2021-05-26T11:33:08.801188Z","shell.execute_reply":"2021-05-26T11:33:08.911755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation = data[numerical_features].corr()\nplt.figure(figsize=(10, 6))\nsns.heatmap(correlation, annot=True, cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:33:11.313226Z","iopub.execute_input":"2021-05-26T11:33:11.313598Z","iopub.status.idle":"2021-05-26T11:33:11.572569Z","shell.execute_reply.started":"2021-05-26T11:33:11.313566Z","shell.execute_reply":"2021-05-26T11:33:11.57155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### При обработке исходного датасета произведем следующие операции:\n- Убираем лишние столбцы\n- Логнормируем числовые признаки\n- Удаляем коррелирующие числовые признаки\n- Сделаем числовой признак с объемом двигателя (из engineDisplacement)\n- Сделаем числовой признак с количеством л.с. автомобиля (из enginePower)\n- Сделаем числовой признак с возрастом автомобиля (из ProductionDate)\n- Сделаем числовой признак среднегодового пробега\n- Нормализуем данные\n- Сделаем Label и OneHot кодирование признаков\n- Заполним Nan средним значением","metadata":{}},{"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()\n    \n    # ################### 1. Предобработка ############################################################## \n    # убираем не нужные для модели признаки\n    df_output.drop(['description','sell_id',], axis = 1, inplace=True)\n    # логнормируем числовые признаки\n    df_output.mileage = np.log(df_output['mileage'] + 1)\n    df_output.modelDate = np.log(df_output['modelDate'] + 1)\n    df_output.productionDate = np.log(df_output['productionDate'] + 1)\n    # удаляем один из коррелирующих признаков modelDate и productionDate\n    #df_output.drop(['modelDate'], axis = 1, inplace=True)\n    \n    # ################### Numerical Features ############################################################## \n    # Далее заполняем пропуски\n    for column in numerical_features:\n        df_output[column].fillna(df_output[column].median(), inplace=True)\n    # тут ваш код по обработке NAN\n    # ....\n    # Сделаем числовой признка из engineDisplacement\n    df_output['engineDisplacement_N'] = df_output['engineDisplacement'].apply(lambda x:\n                                                                           x[:x.find(' LTR')])\n    \n    df_output['engineDisplacement_N'] = df_output['engineDisplacement_N'].apply(lambda x: float(x) if len(x)<4 else 0)\n    \n    # Сделаем числовой признка из enginePower\n    df_output['enginePower_N'] = df_output['enginePower'].apply(lambda x: int(x[:x.find(' N12')]))\n    # Нормализация данных\n    scaler = MinMaxScaler()\n    for column in numerical_features:\n        df_output[column] = scaler.fit_transform(df_output[[column]])[:,0]\n    \n    \n    \n    # ################### Categorical Features ############################################################## \n    # Label Encoding\n    for column in categorical_features:\n        df_output[column] = df_output[column].astype('category').cat.codes\n        \n    # One-Hot Encoding: в pandas есть готовая функция - get_dummies.\n    df_output = pd.get_dummies(df_output, columns=categorical_features, dummy_na=False)\n    # тут ваш код не Encoding фитчей\n    # ....\n    \n    \n    # ################### Feature Engineering ####################################################\n    df_output['how_old'] = df_output['productionDate'].apply(lambda x: pd.Timestamp.today().year - x)\n    df_output['mile_per_year'] = df_output['mileage'] / df_output['how_old']\n    \n    \n    # ################### Clean #################################################### \n    # убираем признаки которые еще не успели обработать, \n    df_output.drop(['vehicleConfiguration'], axis = 1, inplace=True)\n    \n    return df_output","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:18:57.795232Z","iopub.execute_input":"2021-05-29T19:18:57.795593Z","iopub.status.idle":"2021-05-29T19:18:57.814791Z","shell.execute_reply.started":"2021-05-29T19:18:57.795562Z","shell.execute_reply":"2021-05-29T19:18:57.813094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Запускаем и проверяем, что получилось\ndf_preproc = preproc_data(data)\ndf_preproc.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:19:03.02437Z","iopub.execute_input":"2021-05-29T19:19:03.02489Z","iopub.status.idle":"2021-05-29T19:19:03.276319Z","shell.execute_reply.started":"2021-05-29T19:19:03.024842Z","shell.execute_reply":"2021-05-29T19:19:03.274288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split data","metadata":{}},{"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.price.values     # наш таргет\nX = train_data.drop(['price'], axis=1)\nX_sub = test_data.drop(['price'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:19:08.319932Z","iopub.execute_input":"2021-05-29T19:19:08.320319Z","iopub.status.idle":"2021-05-29T19:19:08.530479Z","shell.execute_reply.started":"2021-05-29T19:19:08.320287Z","shell.execute_reply":"2021-05-29T19:19:08.529626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T19:01:03.615811Z","iopub.execute_input":"2021-05-25T19:01:03.616201Z","iopub.status.idle":"2021-05-25T19:01:03.887506Z","shell.execute_reply.started":"2021-05-25T19:01:03.61617Z","shell.execute_reply":"2021-05-25T19:01:03.886639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2: CatBoostRegressor","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True, random_state=RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:19:35.706645Z","iopub.execute_input":"2021-05-29T19:19:35.707249Z","iopub.status.idle":"2021-05-29T19:19:35.738686Z","shell.execute_reply.started":"2021-05-29T19:19:35.707212Z","shell.execute_reply":"2021-05-29T19:19:35.737853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CatBoostRegressor(iterations = 5000,\n                          #depth=10,\n                          #learning_rate = 0.5,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['RMSE', 'MAE'],\n                          od_wait=500,\n                          #task_type='GPU',\n                         )\nmodel.fit(X_train, y_train,\n         eval_set=(X_test, y_test),\n         verbose_eval=100,\n         use_best_model=True,\n         #plot=True\n         )","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-29T19:19:37.068909Z","iopub.execute_input":"2021-05-29T19:19:37.069472Z","iopub.status.idle":"2021-05-29T19:20:16.055617Z","shell.execute_reply.started":"2021-05-29T19:19:37.069436Z","shell.execute_reply":"2021-05-29T19:20:16.054724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predict_catboost = model.predict(X_test)\nprint(f\"TEST mape: {(mape(y_test, test_predict_catboost))*100:0.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:20:16.057696Z","iopub.execute_input":"2021-05-29T19:20:16.058064Z","iopub.status.idle":"2021-05-29T19:20:16.117543Z","shell.execute_reply.started":"2021-05-29T19:20:16.058023Z","shell.execute_reply":"2021-05-29T19:20:16.11653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получили mape: 12.53%. Попробуем улучшить результат с помощью оптимизации (подбора) параметров модели.","metadata":{}},{"cell_type":"markdown","source":"Запустим подбор параметров для Catboost","metadata":{}},{"cell_type":"code","source":"grid = {'learning_rate': [0.03, 0.1, 0.5],\n        'depth': [4, 6, 10],\n        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n\ngrid_search_result = model.grid_search(grid, \n                                       X, \n                                       y, \n                                       plot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Подбор параметров не дал значимого прироста в улучшении результата.","metadata":{}},{"cell_type":"markdown","source":"## Попробуем воспользоваться механизмами AutoML и посмотрим сможет ли это дать улучшения результата.","metadata":{}},{"cell_type":"markdown","source":"Будем пробовать механизмы H20 и TPOT последовательно.","metadata":{}},{"cell_type":"code","source":"!pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o\nimport h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T05:54:48.039211Z","iopub.execute_input":"2021-05-26T05:54:48.039571Z","iopub.status.idle":"2021-05-26T05:55:14.312016Z","shell.execute_reply.started":"2021-05-26T05:54:48.039541Z","shell.execute_reply":"2021-05-26T05:55:14.311165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_h2o = h2o.H2OFrame(train_data)\ntrain, test, valid = train_h2o.split_frame ( ratios = [ .7 , .15 ])\ny = \"price\"\nx_train = train_h2o.columns\nx_train.remove(y)\naml = H2OAutoML(max_runtime_secs=600, seed = 1)\naml.train(x = x_train, y = y, training_frame = train_h2o)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T05:55:28.846977Z","iopub.execute_input":"2021-05-26T05:55:28.847337Z","iopub.status.idle":"2021-05-26T05:55:38.579522Z","shell.execute_reply.started":"2021-05-26T05:55:28.847305Z","shell.execute_reply":"2021-05-26T05:55:38.578355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb = aml.leaderboard\nlb.head(100)\npreds = aml.leader.predict(test_h2o)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T05:55:56.736979Z","iopub.execute_input":"2021-05-26T05:55:56.737339Z","iopub.status.idle":"2021-05-26T05:56:03.00526Z","shell.execute_reply.started":"2021-05-26T05:55:56.737306Z","shell.execute_reply":"2021-05-26T05:56:03.004119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для каачественного подбора модели и параметров требуется большое количество времени и ресурсов (kaggle не позволяет этого сделать)","metadata":{}},{"cell_type":"code","source":"!pip install tpot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tpot import TPOTRegressor\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpot = TPOTRegressor(generations=5, population_size=50, verbosity=2, random_state=42, n_jobs = -1)\ntpot.fit(X_train, y_train)\nprint(tpot.score(X_test, y_test))\n\ntest_tpot = tpot.predict(X_test)\nprint(f\"TEST mape: {(mape(y_test, test_tpot))*100:0.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для расчета на kaggle не хватило памяти :(","metadata":{}},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"sub_predict_catboost = model.predict(X_sub)\nsample_submission['price'] = sub_predict_catboost\nsample_submission.to_csv('catboost_submission2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:00:16.696513Z","iopub.execute_input":"2021-05-26T13:00:16.6969Z","iopub.status.idle":"2021-05-26T13:00:16.757575Z","shell.execute_reply.started":"2021-05-26T13:00:16.696865Z","shell.execute_reply":"2021-05-26T13:00:16.756774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"попробуем еще решение autoML от Yandex \"lightAutoML\". По описанию (https://github.com/sberbank-ai-lab/LightAutoML), проблем с ресурсами быть не должно.","metadata":{}},{"cell_type":"code","source":"!pip install -U lightautoml","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:23:43.384058Z","iopub.execute_input":"2021-05-29T19:23:43.384452Z","iopub.status.idle":"2021-05-29T19:26:07.95352Z","shell.execute_reply.started":"2021-05-29T19:23:43.384422Z","shell.execute_reply":"2021-05-29T19:26:07.951434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standard python libraries\nimport logging\nimport os\nimport time\nimport requests\nlogging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport torch\n\n# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\nfrom lightautoml.utils.profiler import Profiler","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:26:07.960151Z","iopub.execute_input":"2021-05-29T19:26:07.960981Z","iopub.status.idle":"2021-05-29T19:26:12.844845Z","shell.execute_reply.started":"2021-05-29T19:26:07.960919Z","shell.execute_reply":"2021-05-29T19:26:12.843699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_THREADS = 8 # threads cnt for lgbm and linear models\nN_FOLDS = 5 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 1200 # Time in seconds for automl run\nTARGET_NAME = 'price' # Target column name","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:26:12.846975Z","iopub.execute_input":"2021-05-29T19:26:12.847424Z","iopub.status.idle":"2021-05-29T19:26:12.854536Z","shell.execute_reply.started":"2021-05-29T19:26:12.847376Z","shell.execute_reply":"2021-05-29T19:26:12.853569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:26:12.858476Z","iopub.execute_input":"2021-05-29T19:26:12.858855Z","iopub.status.idle":"2021-05-29T19:26:12.911217Z","shell.execute_reply.started":"2021-05-29T19:26:12.858821Z","shell.execute_reply":"2021-05-29T19:26:12.910181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\n\n# # Создаем задание\ntask = Task('reg', loss = 'rmsle', metric = 'rmsle')\n\n# # Создаем роли\nroles = {'target': 'price'}","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:26:22.058089Z","iopub.execute_input":"2021-05-29T19:26:22.058444Z","iopub.status.idle":"2021-05-29T19:26:22.067594Z","shell.execute_reply.started":"2021-05-29T19:26:22.058414Z","shell.execute_reply":"2021-05-29T19:26:22.066347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Сплитанем данные для обучения\ntr_data, te_data = train_test_split(train_data, \n                                     test_size=TEST_SIZE,\n                                     random_state=RANDOM_STATE)\nprint('Data splitted. Parts sizes: tr_data = {}, te_data = {}'.format(tr_data.shape, te_data.shape))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:26:29.698662Z","iopub.execute_input":"2021-05-29T19:26:29.699046Z","iopub.status.idle":"2021-05-29T19:26:29.758906Z","shell.execute_reply.started":"2021-05-29T19:26:29.699013Z","shell.execute_reply":"2021-05-29T19:26:29.757671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# # Train AutoML\nautoml = TabularAutoML(task = task, \n                    timeout = TIMEOUT,\n                    cpu_limit = N_THREADS,\n                    #reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n                     verbose = 1)\noof_pred = automl.fit_predict(tr_data, roles = roles)\n\n# # Predict on test\ntest_pred = automl.predict(te_data)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:26:40.761841Z","iopub.execute_input":"2021-05-29T19:26:40.762293Z","iopub.status.idle":"2021-05-29T19:37:29.401337Z","shell.execute_reply.started":"2021-05-29T19:26:40.762254Z","shell.execute_reply":"2021-05-29T19:37:29.399961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"x","metadata":{}},{"cell_type":"code","source":"test_pred_full = test_pred.data[:, 0].copy().round(0)\nprint(f\"TEST mape: {(mape(te_data['price'].values, test_pred_full))*100:0.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T19:37:29.403863Z","iopub.execute_input":"2021-05-29T19:37:29.404358Z","iopub.status.idle":"2021-05-29T19:37:29.413375Z","shell.execute_reply.started":"2021-05-29T19:37:29.404309Z","shell.execute_reply":"2021-05-29T19:37:29.4118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получили результат mape: 12.06%. С ходу результаты работы autoML радуют. Получен значительный прирост в улучшении результата.","metadata":{}},{"cell_type":"code","source":"sub_predict_automl = automl.predict(X_sub).data[:, 0].copy().round(0)\nsample_submission['price'] = sub_predict_automl\nsample_submission.to_csv('autoML_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:24:40.167763Z","iopub.execute_input":"2021-05-26T13:24:40.168128Z","iopub.status.idle":"2021-05-26T13:24:42.655411Z","shell.execute_reply.started":"2021-05-26T13:24:40.168098Z","shell.execute_reply":"2021-05-26T13:24:42.654227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 3: Tabular NN","metadata":{}},{"cell_type":"markdown","source":"Построим обычную сеть:","metadata":{}},{"cell_type":"code","source":"X_train.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simple Dense NN","metadata":{}},{"cell_type":"markdown","source":"Дополнительно к предложенной в baseline простейшей полносвязной сети добавим слои batch-нормализации. (после каждого полносвязного слоя9)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import regularizers","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:53:03.991647Z","iopub.execute_input":"2021-05-26T13:53:03.99203Z","iopub.status.idle":"2021-05-26T13:53:03.997631Z","shell.execute_reply.started":"2021-05-26T13:53:03.991997Z","shell.execute_reply":"2021-05-26T13:53:03.996256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(256, activation=\"relu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(128, activation=\"elu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(64, activation=\"sigmoid\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(32, activation=\"relu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.5))\nmodel.add(L.Dense(1, activation=\"linear\"))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T20:11:25.681829Z","iopub.execute_input":"2021-05-29T20:11:25.68227Z","iopub.status.idle":"2021-05-29T20:11:25.813276Z","shell.execute_reply.started":"2021-05-29T20:11:25.682237Z","shell.execute_reply":"2021-05-29T20:11:25.811787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T20:11:27.441251Z","iopub.execute_input":"2021-05-29T20:11:27.441632Z","iopub.status.idle":"2021-05-29T20:11:27.491514Z","shell.execute_reply.started":"2021-05-29T20:11:27.4416Z","shell.execute_reply":"2021-05-29T20:11:27.490326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(0.0005)\nmodel.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T20:11:34.034149Z","iopub.execute_input":"2021-05-29T20:11:34.034525Z","iopub.status.idle":"2021-05-29T20:11:34.048907Z","shell.execute_reply.started":"2021-05-29T20:11:34.034494Z","shell.execute_reply":"2021-05-29T20:11:34.047959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting callbacks.\ncheckpoint = ModelCheckpoint('../working/best_model.hdf5' , monitor=['val_MAPE'], verbose=0  , mode='min')\nearlystop = EarlyStopping(monitor='val_MAPE', patience=50, restore_best_weights=True,)\ncallbacks_list = [checkpoint, earlystop]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T20:11:45.260291Z","iopub.execute_input":"2021-05-29T20:11:45.260652Z","iopub.status.idle":"2021-05-29T20:11:45.26608Z","shell.execute_reply.started":"2021-05-29T20:11:45.260622Z","shell.execute_reply":"2021-05-29T20:11:45.265239Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tabular NN training.\nhistory = model.fit(\n    X_train,\n    y_train,\n    batch_size=512,\n    epochs=1000,\n    validation_data=(X_test, y_test),\n    callbacks=callbacks_list,\n    verbose=0\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T20:11:47.871286Z","iopub.execute_input":"2021-05-29T20:11:47.871828Z","iopub.status.idle":"2021-05-29T20:19:05.876524Z","shell.execute_reply.started":"2021-05-29T20:11:47.871794Z","shell.execute_reply":"2021-05-29T20:19:05.875215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history.history['MAPE'], label='train')\nplt.plot(history.history['val_MAPE'], label='test')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T20:19:05.879269Z","iopub.execute_input":"2021-05-29T20:19:05.879784Z","iopub.status.idle":"2021-05-29T20:19:06.040759Z","shell.execute_reply.started":"2021-05-29T20:19:05.879735Z","shell.execute_reply":"2021-05-29T20:19:06.039671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving model + Loading best weights.\nmodel.load_weights('../working/best_model.hdf5')\nmodel.save('../working/nn_1.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Итак, простая нейронная сеть нам дала 18,2%","metadata":{}},{"cell_type":"markdown","source":"### Fit","metadata":{}},{"cell_type":"code","source":"test_predict_nn1 = model.predict(X_test)\nprint(f\"TEST mape: {(mape(y_test, test_predict_nn1[:,0]))*100:0.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T12:15:45.618388Z","iopub.execute_input":"2021-05-26T12:15:45.618857Z","iopub.status.idle":"2021-05-26T12:15:45.763666Z","shell.execute_reply.started":"2021-05-26T12:15:45.618814Z","shell.execute_reply":"2021-05-26T12:15:45.762678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_predict_nn1 = model.predict(X_sub)\nsample_submission['price'] = sub_predict_nn1[:,0]\nsample_submission.to_csv('nn1_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T12:16:19.409397Z","iopub.execute_input":"2021-05-26T12:16:19.409799Z","iopub.status.idle":"2021-05-26T12:16:19.603384Z","shell.execute_reply.started":"2021-05-26T12:16:19.409757Z","shell.execute_reply":"2021-05-26T12:16:19.602546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Рекомендации для улучшения Model 3:    \n* В нейросеть желательно подавать данные с распределением, близким к нормальному, поэтому от некоторых числовых признаков имеет смысл взять логарифм перед нормализацией. Пример:\n`modelDateNorm = np.log(2020 - data['modelDate'])`\nСтатья по теме: https://habr.com/ru/company/ods/blog/325422\n\n* Извлечение числовых значений из текста:\nПарсинг признаков 'engineDisplacement', 'enginePower', 'Владение' для извлечения числовых значений.\n\n* Cокращение размерности категориальных признаков\nПризнак name 'name' содержит данные, которые уже есть в других столбцах ('enginePower', 'engineDisplacement', 'vehicleTransmission'), поэтому эти данные можно удалить. Затем следует еще сильнее сократить размерность, например, выделив наличие xDrive в качестве отдельного признака.","metadata":{}},{"cell_type":"markdown","source":"# Model 4: NLP + Multiple Inputs","metadata":{}},{"cell_type":"markdown","source":"Для начала поработаем с полем текстового описания объявления (Description). будем использовать лемматизацию с спомощью пакета pymorphy. А делее токенизируем наш текст (переведем в векторный вид)","metadata":{}},{"cell_type":"code","source":"data.description","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:34:00.207472Z","iopub.execute_input":"2021-05-26T14:34:00.207836Z","iopub.status.idle":"2021-05-26T14:34:00.21833Z","shell.execute_reply.started":"2021-05-26T14:34:00.207805Z","shell.execute_reply":"2021-05-26T14:34:00.217227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pymorphy2","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:47:35.486897Z","iopub.execute_input":"2021-05-26T14:47:35.487299Z","iopub.status.idle":"2021-05-26T14:47:47.925006Z","shell.execute_reply.started":"2021-05-26T14:47:35.487264Z","shell.execute_reply":"2021-05-26T14:47:47.923886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pymorphy2","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:54:45.350794Z","iopub.execute_input":"2021-05-26T15:54:45.351287Z","iopub.status.idle":"2021-05-26T15:54:45.377217Z","shell.execute_reply.started":"2021-05-26T15:54:45.351252Z","shell.execute_reply":"2021-05-26T15:54:45.375922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pymystem3\n!pip install --upgrade pip","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom pymystem3 import Mystem\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:15:42.139869Z","iopub.execute_input":"2021-05-26T16:15:42.140207Z","iopub.status.idle":"2021-05-26T16:15:42.144693Z","shell.execute_reply.started":"2021-05-26T16:15:42.14018Z","shell.execute_reply":"2021-05-26T16:15:42.143773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.description = data.description.apply(lambda x: lemmatize(x))\ndata.description[5]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:36:38.128381Z","iopub.execute_input":"2021-05-26T16:36:38.128812Z","iopub.status.idle":"2021-05-26T16:42:08.791912Z","shell.execute_reply.started":"2021-05-26T16:36:38.128775Z","shell.execute_reply":"2021-05-26T16:42:08.790939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_train = data.description.iloc[X_train.index]\ntext_test = data.description.iloc[X_test.index]\ntext_sub = data.description.iloc[X_sub.index]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:46:37.994966Z","iopub.execute_input":"2021-05-26T16:46:37.9953Z","iopub.status.idle":"2021-05-26T16:46:38.003313Z","shell.execute_reply.started":"2021-05-26T16:46:37.995268Z","shell.execute_reply":"2021-05-26T16:46:38.002323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TOKENIZER\n# The maximum number of words to be used. (most frequent)\nMAX_WORDS = 100000\n# Max number of words in each complaint.\nMAX_SEQUENCE_LENGTH = 256","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:46:39.551893Z","iopub.execute_input":"2021-05-26T16:46:39.552226Z","iopub.status.idle":"2021-05-26T16:46:39.556127Z","shell.execute_reply.started":"2021-05-26T16:46:39.552199Z","shell.execute_reply":"2021-05-26T16:46:39.555114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenizer","metadata":{}},{"cell_type":"code","source":"%%time\ntokenize = Tokenizer(num_words=MAX_WORDS)\ntokenize.fit_on_texts(data.description)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:46:49.809702Z","iopub.execute_input":"2021-05-26T16:46:49.810178Z","iopub.status.idle":"2021-05-26T16:46:51.048855Z","shell.execute_reply.started":"2021-05-26T16:46:49.810147Z","shell.execute_reply":"2021-05-26T16:46:51.047769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenize.word_index","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntext_train_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_train), maxlen=MAX_SEQUENCE_LENGTH)\ntext_test_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_test), maxlen=MAX_SEQUENCE_LENGTH)\ntext_sub_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_sub), maxlen=MAX_SEQUENCE_LENGTH)\n\nprint(text_train_sequences.shape, text_test_sequences.shape, text_sub_sequences.shape, )","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:46:57.725213Z","iopub.execute_input":"2021-05-26T16:46:57.72557Z","iopub.status.idle":"2021-05-26T16:46:59.058412Z","shell.execute_reply.started":"2021-05-26T16:46:57.725535Z","shell.execute_reply":"2021-05-26T16:46:59.057415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# вот так теперь выглядит наш текст\nprint(text_train.iloc[6])\nprint(text_train_sequences[6])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:47:04.043905Z","iopub.execute_input":"2021-05-26T16:47:04.044221Z","iopub.status.idle":"2021-05-26T16:47:04.053386Z","shell.execute_reply.started":"2021-05-26T16:47:04.044194Z","shell.execute_reply":"2021-05-26T16:47:04.052408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RNN NLP","metadata":{}},{"cell_type":"markdown","source":"Создаем 1-й вход для ","metadata":{}},{"cell_type":"code","source":"model_nlp = Sequential()\nmodel_nlp.add(L.Input(shape=MAX_SEQUENCE_LENGTH, name=\"seq_description\"))\nmodel_nlp.add(L.Embedding(len(tokenize.word_index)+1, MAX_SEQUENCE_LENGTH,))\nmodel_nlp.add(L.LSTM(256, return_sequences=True))\nmodel_nlp.add(L.Dropout(0.5))\nmodel_nlp.add(L.LSTM(128,))\nmodel_nlp.add(L.Dropout(0.25))\nmodel_nlp.add(L.Dense(64, activation=\"relu\"))\nmodel_nlp.add(L.Dropout(0.25))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:47:30.766402Z","iopub.execute_input":"2021-05-26T16:47:30.766747Z","iopub.status.idle":"2021-05-26T16:47:31.300677Z","shell.execute_reply.started":"2021-05-26T16:47:30.766708Z","shell.execute_reply":"2021-05-26T16:47:31.299807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MLP","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(256, activation=\"relu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(128, activation=\"elu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(64, activation=\"sigmoid\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(32, activation=\"relu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.5))\nmodel.add(L.Dense(1, activation=\"linear\"))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:47:38.31547Z","iopub.execute_input":"2021-05-26T16:47:38.315808Z","iopub.status.idle":"2021-05-26T16:47:38.359233Z","shell.execute_reply.started":"2021-05-26T16:47:38.315779Z","shell.execute_reply":"2021-05-26T16:47:38.358505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multiple Inputs NN","metadata":{}},{"cell_type":"code","source":"combinedInput = L.concatenate([model_nlp.output, model_mlp.output])\n# being our regression head\nhead = L.Dense(64, activation=\"relu\")(combinedInput)\nhead = L.Dense(1, activation=\"linear\")(head)\n\nmodel = Model(inputs=[model_nlp.input, model_mlp.input], outputs=head)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:47:44.294578Z","iopub.execute_input":"2021-05-26T16:47:44.295185Z","iopub.status.idle":"2021-05-26T16:47:44.31976Z","shell.execute_reply.started":"2021-05-26T16:47:44.295147Z","shell.execute_reply":"2021-05-26T16:47:44.319013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-26T16:47:47.395101Z","iopub.execute_input":"2021-05-26T16:47:47.395671Z","iopub.status.idle":"2021-05-26T16:47:47.457053Z","shell.execute_reply.started":"2021-05-26T16:47:47.395632Z","shell.execute_reply":"2021-05-26T16:47:47.4558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fit","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(0.01)\nmodel.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:47:57.247156Z","iopub.execute_input":"2021-05-26T16:47:57.247512Z","iopub.status.idle":"2021-05-26T16:47:57.260565Z","shell.execute_reply.started":"2021-05-26T16:47:57.247483Z","shell.execute_reply":"2021-05-26T16:47:57.259675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('../working/best_model.hdf5', monitor=['val_MAPE'], verbose=0, mode='min')\nearlystop = EarlyStopping(monitor='val_MAPE', patience=10, restore_best_weights=True,)\ncallbacks_list = [checkpoint, earlystop]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:47:59.54511Z","iopub.execute_input":"2021-05-26T16:47:59.545438Z","iopub.status.idle":"2021-05-26T16:47:59.551365Z","shell.execute_reply.started":"2021-05-26T16:47:59.54541Z","shell.execute_reply":"2021-05-26T16:47:59.550281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([text_train_sequences, X_train], y_train,\n                    batch_size=512,\n                    epochs=500, # фактически мы обучаем пока EarlyStopping не остановит обучение\n                    validation_data=([text_test_sequences, X_test], y_test),\n                    callbacks=callbacks_list\n                   )","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-26T16:48:01.841833Z","iopub.execute_input":"2021-05-26T16:48:01.84216Z","iopub.status.idle":"2021-05-26T17:58:43.515154Z","shell.execute_reply.started":"2021-05-26T16:48:01.842132Z","shell.execute_reply":"2021-05-26T17:58:43.512458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"x","metadata":{}},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history.history['MAPE'], label='train')\nplt.plot(history.history['val_MAPE'], label='test')\nplt.show();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../working/best_model.hdf5')\nmodel.save('../working/nn_mlp_nlp.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predict_nn2 = model.predict([text_test_sequences, X_test])\nprint(f\"TEST mape: {(mape(y_test, test_predict_nn2[:,0]))*100:0.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получили результат 16,2%","metadata":{}},{"cell_type":"code","source":"sub_predict_nn2 = model.predict([text_sub_sequences, X_sub])\nsample_submission['price'] = sub_predict_nn2[:,0]\nsample_submission.to_csv('nn2_submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Идеи для улучшения NLP части:\n* Выделить из описаний часто встречающиеся блоки текста, заменив их на кодовые слова или удалив\n* Сделать предобработку текста, например, сделать лемматизацию - алгоритм ставящий все слова в форму по умолчанию (глаголы в инфинитив и т. д.), чтобы токенайзер не преобразовывал разные формы слова в разные числа\nСтатья по теме: https://habr.com/ru/company/Voximplant/blog/446738/\n* Поработать над алгоритмами очистки и аугментации текста","metadata":{}},{"cell_type":"markdown","source":"# Model 5: Добавляем картинки","metadata":{}},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"code","source":"# убедимся, что цены и фото подгрузились верно\nplt.figure(figsize = (12,8))\n\nrandom_image = train.sample(n = 9)\nrandom_image_paths = random_image['sell_id'].values\nrandom_image_cat = random_image['price'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(DATA_DIR+'img/img/' + str(path) + '.jpg')\n    plt.subplot(3, 3, index + 1)\n    plt.imshow(im)\n    plt.title('price: ' + str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size = (320, 240)\n\ndef get_image_array(index):\n    images_train = []\n    for index, sell_id in enumerate(data['sell_id'].iloc[index].values):\n        image = cv2.imread(DATA_DIR + 'img/img/' + str(sell_id) + '.jpg')\n        assert(image is not None)\n        image = cv2.resize(image, size)\n        images_train.append(image)\n    images_train = np.array(images_train)\n    print('images shape', images_train.shape, 'dtype', images_train.dtype)\n    return(images_train)\n\nimages_train = get_image_array(X_train.index)\nimages_test = get_image_array(X_test.index)\nimages_sub = get_image_array(X_sub.index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### albumentations","metadata":{}},{"cell_type":"code","source":"from albumentations import (\n    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n)\n\n\n#пример взят из официальной документации: https://albumentations.readthedocs.io/en/latest/examples.html\naugmentation = Compose([\n    HorizontalFlip(),\n    OneOf([\n        IAAAdditiveGaussianNoise(),\n        GaussNoise(),\n    ], p=0.2),\n    OneOf([\n        MotionBlur(p=0.2),\n        MedianBlur(blur_limit=3, p=0.1),\n        Blur(blur_limit=3, p=0.1),\n    ], p=0.2),\n    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=1),\n    OneOf([\n        OpticalDistortion(p=0.3),\n        GridDistortion(p=0.1),\n        IAAPiecewiseAffine(p=0.3),\n    ], p=0.2),\n    OneOf([\n        CLAHE(clip_limit=2),\n        IAASharpen(),\n        IAAEmboss(),\n        RandomBrightnessContrast(),\n    ], p=0.3),\n    HueSaturationValue(p=0.3),\n], p=1)\n\n#пример\nplt.figure(figsize = (12,8))\nfor i in range(9):\n    img = augmentation(image = images_train[0])['image']\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(img)\n    plt.axis('off')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_augmentations(images):\n  print('применение аугментаций', end = '')\n  augmented_images = np.empty(images.shape)\n  for i in range(images.shape[0]):\n    if i % 200 == 0:\n      print('.', end = '')\n    augment_dict = augmentation(image = images[i])\n    augmented_image = augment_dict['image']\n    augmented_images[i] = augmented_image\n  print('')\n  return augmented_images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## tf.data.Dataset\nЕсли все изображения мы будем хранить в памяти, то может возникнуть проблема ее нехватки. Не храните все изображения в памяти целиком!\n\nМетод .fit() модели keras может принимать либо данные в виде массивов или тензоров, либо разного рода итераторы, из которых наиболее современным и гибким является [tf.data.Dataset](https://www.tensorflow.org/guide/data). Он представляет собой конвейер, то есть мы указываем, откуда берем данные и какую цепочку преобразований с ними выполняем. Далее мы будем работать с tf.data.Dataset.\n\nDataset хранит информацию о конечном или бесконечном наборе кортежей (tuple) с данными и может возвращать эти наборы по очереди. Например, данными могут быть пары (input, target) для обучения нейросети. С данными можно осуществлять преобразования, которые осуществляются по мере необходимости ([lazy evaluation](https://ru.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BD%D0%B8%D0%B2%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F)).\n\n`tf.data.Dataset.from_tensor_slices(data)` - создает датасет из данных, которые представляют собой либо массив, либо кортеж из массивов. Деление осуществляется по первому индексу каждого массива. Например, если `data = (np.zeros((128, 256, 256)), np.zeros(128))`, то датасет будет содержать 128 элементов, каждый из которых содержит один массив 256x256 и одно число.\n\n`dataset2 = dataset1.map(func)` - применение функции к датасету; функция должна принимать столько аргументов, каков размер кортежа в датасете 1 и возвращать столько, сколько нужно иметь в датасете 2. Пусть, например, датасет содержит изображения и метки, а нам нужно создать датасет только из изображений, тогда мы напишем так: `dataset2 = dataset.map(lambda img, label: img)`.\n\n`dataset2 = dataset1.batch(8)` - группировка по батчам; если датасет 2 должен вернуть один элемент, то он берет из датасета 1 восемь элементов, склеивает их (нулевой индекс результата - номер элемента) и возвращает.\n\n`dataset.__iter__()` - превращение датасета в итератор, из которого можно получать элементы методом `.__next__()`. Итератор, в отличие от самого датасета, хранит позицию текущего элемента. Можно также перебирать датасет циклом for.\n\n`dataset2 = dataset1.repeat(X)` - датасет 2 будет повторять датасет 1 X раз.\n\nЕсли нам нужно взять из датасета 1000 элементов и использовать их как тестовые, а остальные как обучающие, то мы напишем так:\n\n`test_dataset = dataset.take(1000)\ntrain_dataset = dataset.skip(1000)`\n\nДатасет по сути неизменен: такие операции, как map, batch, repeat, take, skip никак не затрагивают оригинальный датасет. Если датасет хранит элементы [1, 2, 3], то выполнив 3 раза подряд функцию dataset.take(1) мы получим 3 новых датасета, каждый из которых вернет число 1. Если же мы выполним функцию dataset.skip(1), мы получим датасет, возвращающий числа [2, 3], но исходный датасет все равно будет возвращать [1, 2, 3] каждый раз, когда мы его перебираем.\n\ntf.Dataset всегда выполняется в graph-режиме (в противоположность eager-режиму), поэтому либо преобразования (`.map()`) должны содержать только tensorflow-функции, либо мы должны использовать tf.py_function в качестве обертки для функций, вызываемых в `.map()`. Подробнее можно прочитать [здесь](https://www.tensorflow.org/guide/data#applying_arbitrary_python_logic).","metadata":{}},{"cell_type":"code","source":"# NLP part\ntokenize = Tokenizer(num_words=MAX_WORDS)\ntokenize.fit_on_texts(data.description)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_image(image):\n    return augmentation(image = image.numpy())['image']\n\ndef tokenize_(descriptions):\n  return sequence.pad_sequences(tokenize.texts_to_sequences(descriptions), maxlen = MAX_SEQUENCE_LENGTH)\n\ndef tokenize_text(text):\n    return tokenize_([text.numpy().decode('utf-8')])[0]\n\ndef tf_process_train_dataset_element(image, table_data, text, price):\n    im_shape = image.shape\n    [image,] = tf.py_function(process_image, [image], [tf.uint8])\n    image.set_shape(im_shape)\n    [text,] = tf.py_function(tokenize_text, [text], [tf.int32])\n    return (image, table_data, text), price\n\ndef tf_process_val_dataset_element(image, table_data, text, price):\n    [text,] = tf.py_function(tokenize_text, [text], [tf.int32])\n    return (image, table_data, text), price\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    images_train, X_train, data.description.iloc[X_train.index], y_train\n    )).map(tf_process_train_dataset_element)\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    images_test, X_test, data.description.iloc[X_test.index], y_test\n    )).map(tf_process_val_dataset_element)\n\ny_sub = np.zeros(len(X_sub))\nsub_dataset = tf.data.Dataset.from_tensor_slices((\n    images_sub, X_sub, data.description.iloc[X_sub.index], y_sub\n    )).map(tf_process_val_dataset_element)\n\n#проверяем, что нет ошибок (не будет выброшено исключение):\ntrain_dataset.__iter__().__next__();\ntest_dataset.__iter__().__next__();\nsub_dataset.__iter__().__next__();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Строим сверточную сеть для анализа изображений без \"головы\"","metadata":{}},{"cell_type":"code","source":"#нормализация включена в состав модели EfficientNetB3, поэтому на вход она принимает данные типа uint8\nefficientnet_model = tf.keras.applications.efficientnet.EfficientNetB3(weights = 'imagenet', include_top = False, input_shape = (size[1], size[0], 3))\nefficientnet_output = L.GlobalAveragePooling2D()(efficientnet_model.output)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#строим нейросеть для анализа табличных данных\ntabular_model = Sequential()\nmodel.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(256, activation=\"relu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(128, activation=\"elu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(64, activation=\"sigmoid\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(32, activation=\"relu\"))\n#model.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.5))\nmodel.add(L.Dense(1, activation=\"linear\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NLP\nnlp_model = Sequential([\n    L.Input(shape=MAX_SEQUENCE_LENGTH, name=\"seq_description\"),\n    L.Embedding(len(tokenize.word_index)+1, MAX_SEQUENCE_LENGTH,),\n    L.LSTM(256, return_sequences=True),\n    L.Dropout(0.5),\n    L.LSTM(128),\n    L.Dropout(0.25),\n    L.Dense(64),\n    ])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#объединяем выходы трех нейросетей\ncombinedInput = L.concatenate([efficientnet_output, tabular_model.output, nlp_model.output])\n\n# being our regression head\nhead = L.Dense(256, activation=\"relu\")(combinedInput)\nhead = L.Dense(1,)(head)\n\nmodel = Model(inputs=[efficientnet_model.input, tabular_model.input, nlp_model.input], outputs=head)\nmodel.summary()","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(0.005)\nmodel.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('../working/best_model.hdf5', monitor=['val_MAPE'], verbose=0, mode='min')\nearlystop = EarlyStopping(monitor='val_MAPE', patience=10, restore_best_weights=True,)\ncallbacks_list = [checkpoint, earlystop]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset.batch(30),\n                    epochs=100,\n                    validation_data = test_dataset.batch(30),\n                    callbacks=callbacks_list\n                   )","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history.history['MAPE'], label='train')\nplt.plot(history.history['val_MAPE'], label='test')\nplt.show();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../working/best_model.hdf5')\nmodel.save('../working/nn_final.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predict_nn3 = model.predict(test_dataset.batch(30))\nprint(f\"TEST mape: {(mape(y_test, test_predict_nn3[:,0]))*100:0.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получили результат 15.4%","metadata":{}},{"cell_type":"code","source":"sub_predict_nn3 = model.predict(sub_dataset.batch(30))\nsample_submission['price'] = sub_predict_nn3[:,0]\nsample_submission.to_csv('nn3_submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Попробуем увеличить сложность сети из того же пакета (выберем В6) и применим fine-tuning + добавим в callbacks динамическое снижение LR**","metadata":{}},{"cell_type":"code","source":"efficientnet_model = tf.keras.applications.efficientnet.EfficientNetB6(weights = 'imagenet', include_top = False, input_shape = (size[1], size[0], 3))\nefficientnet_output = L.GlobalAveragePooling2D()(efficientnet_model.output)\n\nefficientnet_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = 400\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in efficientnet_model.layers[:fine_tune_at]:\n  layer.trainable =  False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#объединяем выходы трех нейросетей\ncombinedInput = L.concatenate([efficientnet_output, tabular_model.output, nlp_model.output])\n\n# being our regression head\nhead = L.Dense(256, activation=\"relu\")(combinedInput)\nhead = L.Dense(1,)(head)\n\nmodel = Model(inputs=[efficientnet_model.input, tabular_model.input, nlp_model.input], outputs=head)\nmodel.summary()\n\noptimizer = tf.keras.optimizers.Adam(0.005)\nmodel.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('../working/best_model.hdf5', monitor=['val_MAPE'], verbose=0, mode='min')\nearlystop = EarlyStopping(monitor='val_MAPE', patience=10, restore_best_weights=True,)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.25,\n                              patience=2,\n                              min_lr=0.0000001,\n                              verbose=1,\n                              mode='auto')\ncallbacks_list = [checkpoint, earlystop, reduce_lr]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset.batch(30),\n                    epochs=100,\n                    validation_data = test_dataset.batch(30),\n                    callbacks=callbacks_list\n                   )\nmodel.load_weights('../working/best_model.hdf5')\nmodel.save('../working/nn_final.hdf5')\n\ntest_predict_nn3 = model.predict(test_dataset.batch(30))\nprint(f\"TEST mape: {(mape(y_test, test_predict_nn3[:,0]))*100:0.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"разморозим 75% головы","metadata":{}},{"cell_type":"code","source":"efficientnet_model = tf.keras.applications.efficientnet.EfficientNetB6(weights = 'imagenet', include_top = False, input_shape = (size[1], size[0], 3))\nefficientnet_output = L.GlobalAveragePooling2D()(efficientnet_model.output)\n\nefficientnet_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = 200\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in efficientnet_model.layers[:fine_tune_at]:\n  layer.trainable =  False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#объединяем выходы трех нейросетей\ncombinedInput = L.concatenate([efficientnet_output, tabular_model.output, nlp_model.output])\n\n# being our regression head\nhead = L.Dense(256, activation=\"relu\")(combinedInput)\nhead = L.Dense(1,)(head)\n\nmodel = Model(inputs=[efficientnet_model.input, tabular_model.input, nlp_model.input], outputs=head)\nmodel.summary()\n\noptimizer = tf.keras.optimizers.Adam(0.005)\nmodel.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset.batch(30),\n                    epochs=100,\n                    validation_data = test_dataset.batch(30),\n                    callbacks=callbacks_list\n                   )\nmodel.load_weights('../working/best_model.hdf5')\nmodel.save('../working/nn_final.hdf5')\n\ntest_predict_nn3 = model.predict(test_dataset.batch(30))\nprint(f\"TEST mape: {(mape(y_test, test_predict_nn3[:,0]))*100:0.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получили значение 12.3%","metadata":{}},{"cell_type":"markdown","source":"\n#### Общие рекомендации:\n* Попробовать разные архитектуры\n* Провести более детальный анализ результатов\n* Попробовать различные подходы в управление LR и оптимизаторы\n* Поработать с таргетом\n* Использовать Fine-tuning\n\n#### Tabular\n* В нейросеть желательно подавать данные с распределением, близким к нормальному, поэтому от некоторых числовых признаков имеет смысл взять логарифм перед нормализацией. Пример:\n`modelDateNorm = np.log(2020 - data['modelDate'])`\nСтатья по теме: https://habr.com/ru/company/ods/blog/325422\n\n* Извлечение числовых значений из текста:\nПарсинг признаков 'engineDisplacement', 'enginePower', 'Владение' для извлечения числовых значений.\n\n* Cокращение размерности категориальных признаков\nПризнак name 'name' содержит данные, которые уже есть в других столбцах ('enginePower', 'engineDisplacement', 'vehicleTransmission'). Можно удалить эти данные. Затем можно еще сильнее сократить размерность, например выделив наличие xDrive в качестве отдельного признака.\n\n* Поработать над Feature engineering\n\n\n\n#### NLP\n* Выделить из описаний часто встречающиеся блоки текста, заменив их на кодовые слова или удалив\n* Сделать предобработку текста, например сделать лемматизацию - алгоритм ставящий все слова в форму по умолчанию (глаголы в инфинитив и т. д.), чтобы токенайзер не преобразовывал разные формы слова в разные числа\nСтатья по теме: https://habr.com/ru/company/Voximplant/blog/446738/\n* Поработать над алгоритмами очистки и аугментации текста\n\n\n\n#### CV\n* Попробовать различные аугментации\n* Fine-tuning","metadata":{}},{"cell_type":"markdown","source":"# Выводы","metadata":{}},{"cell_type":"markdown","source":"В рамках работы были использованы большинство предложенией по улучшению модели. Дополнительно были рассмотрены механизмы autoML различных библиотек.\n\nИтого наилучший результат получился обычным ML способом (AutoML) при этом это заняло на порядок меньше времени, чем построение сложной нейросети.","metadata":{}},{"cell_type":"markdown","source":"# Blend","metadata":{}},{"cell_type":"code","source":"blend_predict = (test_predict_catboost + test_predict_nn3[:,0]) / 2\nprint(f\"TEST mape: {(mape(y_test, blend_predict))*100:0.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blend_sub_predict = (sub_predict_catboost + sub_predict_nn3[:,0]) / 2\nsample_submission['price'] = blend_sub_predict\nsample_submission.to_csv('blend_submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Bonus: проброс признака","metadata":{}},{"cell_type":"code","source":"# MLP\nmodel_mlp = Sequential()\nmodel_mlp.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\nmodel_mlp.add(L.Dropout(0.5))\nmodel_mlp.add(L.Dense(256, activation=\"relu\"))\nmodel_mlp.add(L.Dropout(0.5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FEATURE Input\n# Iput\nproductiondate = L.Input(shape=[1], name=\"productiondate\")\n# Embeddings layers\nemb_productiondate = L.Embedding(len(X.productionDate.unique().tolist())+1, 20)(productiondate)\nf_productiondate = L.Flatten()(emb_productiondate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combinedInput = L.concatenate([model_mlp.output, f_productiondate,])\n# being our regression head\nhead = L.Dense(64, activation=\"relu\")(combinedInput)\nhead = L.Dense(1, activation=\"linear\")(head)\n\nmodel = Model(inputs=[model_mlp.input, productiondate], outputs=head)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(0.01)\nmodel.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([X_train, X_train.productionDate.values], y_train,\n                    batch_size=512,\n                    epochs=500, # фактически мы обучаем пока EarlyStopping не остановит обучение\n                    validation_data=([X_test, X_test.productionDate.values], y_test),\n                    callbacks=callbacks_list\n                   )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../working/best_model.hdf5')\ntest_predict_nn_bonus = model.predict([X_test, X_test.productionDate.values])\nprint(f\"TEST mape: {(mape(y_test, test_predict_nn_bonus[:,0]))*100:0.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ","metadata":{},"execution_count":null,"outputs":[]}]}